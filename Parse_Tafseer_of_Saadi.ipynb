{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5b78c1-50e2-4bb6-a387-18cb855e72dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymupdf\n",
    "# !pip install pdfplumber\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c35c0d1-013c-4fc8-9f31-22d18402ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re\n",
    "import pandas as pd\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e6a2d58d-98ed-4cb3-8e2d-5f7d7cc05d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(arr):\n",
    "    text = arr[0] \n",
    "    tafseer = ''\n",
    "    for i in range(1, len(arr) - 1):\n",
    "        tafseer += ' '+arr[i] + \"\\\\n\\\\n\"\n",
    "    tafseer += ' ' + arr[-1]\n",
    "\n",
    "    return text + f'[[{tafseer}]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "62d75925-4da4-4105-a078-188b9cfe2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_continuations(array):\n",
    "    merged_array = []\n",
    "    i = 0\n",
    "    while i < len(array):\n",
    "        current_element = array[i]\n",
    "        while i + 1 < len(array) and array[i + 1][0].islower():\n",
    "            if current_element[-1] == '-':\n",
    "                current_element += array[i + 1]\n",
    "            else:\n",
    "                current_element += ' ' + array[i + 1]\n",
    "            i += 1\n",
    "        merged_array.append(current_element)\n",
    "        i += 1\n",
    "    return merged_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f574104-55ac-4e08-9277-708a6003e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_newlines_to_text(text1, text2):\n",
    "    #Split the second text by symbols \\n\\n\n",
    "    parts = text2.split('\\\\n\\\\n')\n",
    "    \n",
    "    # Initialized result and reference position\n",
    "    result = []\n",
    "    last_pos = 0\n",
    "    \n",
    "    for part in parts:\n",
    "        # Looking for a part of the text from the second text in the first text\n",
    "        idx = text1.find(part.strip(), last_pos)\n",
    "        \n",
    "        if idx != -1:\n",
    "            # Add text from the last position to the found position\n",
    "            result.append(text1[last_pos:idx])\n",
    "            # Add \\n\\n\n",
    "            result.append('\\n\\n ')\n",
    "            # Add the found part of the text\n",
    "            result.append(text1[idx:idx + len(part.strip())])\n",
    "            # Updating the current position\n",
    "            last_pos = idx + len(part.strip())\n",
    "    \n",
    "    # Add the remaining text after the last fragment\n",
    "    result.append(text1[last_pos:])\n",
    "    \n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "119a86fa-0d32-4dbd-87d1-596195d64e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(array):\n",
    "    return [re.sub(r'\\s+', ' ', item).strip().replace('-', '') for item in array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c40faf69-627f-4683-beaa-fd56cbc1e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Al-Faatiha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "2e9a65a1-62c6-428d-9074-e0ddfc4b1e60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Al_Faatiha = text[1]\n",
    "# Al_Faatiha_corrected = []\n",
    "\n",
    "# pattern = r'\\(\\d+\\)'\n",
    "\n",
    "# ayahs = re.split(pattern, Al_Faatiha)\n",
    "# ayahs = [section.strip().replace('\\n', '') for section in ayahs if section.strip()]\n",
    "\n",
    "\n",
    "\n",
    "# for ayah in ayahs:\n",
    "#     ayah = ayah.split('--- Paragraph ---')\n",
    "#     if len(ayah) > 1:\n",
    "        \n",
    "#         ayah_splited = merge_continuations(ayah)\n",
    "#         cleaned_array = remove_extra_spaces(ayah_splited)\n",
    "        \n",
    "#         Al_Faatiha_corrected.append(convert(cleaned_array))\n",
    "#     else:\n",
    "#         Al_Faatiha_corrected.append(ayah[0])\n",
    "\n",
    "# data = { \"surahs\": [ {\"number\":1, \"EnglishName\": \"Al-Faatiha\", \"ayahs\":[]}, {\"number\":2, \"EnglishName\": \"Al-Baqarah\", 'ayahs':[]} ]}\n",
    "# cnt = -1\n",
    "\n",
    "# for new_ayah in Al_Faatiha_corrected:\n",
    "#     cnt += 1\n",
    "#     d = {\"number\":cnt, \"text\":new_ayah}\n",
    "#     data[\"surahs\"][0][\"ayahs\"].append(d)\n",
    "\n",
    "# # print(convert(cleaned_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "a2f58193-2185-4410-a800-9294ace98ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Al - Baqarah\n",
    "\n",
    "\n",
    "# Al_Baqarah = text[2]\n",
    "# Al_Baqarah_corrected = []\n",
    "\n",
    "# pattern = r'\\(\\d+\\)'\n",
    "\n",
    "# ayahs = re.split(pattern, Al_Baqarah)\n",
    "# ayahs = [section.strip().replace('\\n', '') for section in ayahs if section.strip()]\n",
    "\n",
    "\n",
    "\n",
    "# for ayah in ayahs:\n",
    "#     ayah = ayah.split('--- Paragraph ---')\n",
    "    \n",
    "#     if len(ayah) > 1:\n",
    "        \n",
    "#         ayah_splited = merge_continuations(ayah)\n",
    "        \n",
    "#         cleaned_array = remove_extra_spaces(ayah_splited)\n",
    "        \n",
    "#         Al_Baqarah_corrected.append(convert(cleaned_array))\n",
    "#     else:\n",
    "#         Al_Baqarah_corrected.append(ayah[0])\n",
    "\n",
    "# cnt = -1\n",
    "\n",
    "\n",
    "# for new_ayah in Al_Baqarah_corrected:\n",
    "#     cnt += 1\n",
    "#     d = {\"number\":cnt, \"text\":new_ayah}\n",
    "#     data[\"surahs\"][1][\"ayahs\"].append(d)\n",
    "\n",
    "# # print(data[\"surahs\"][1][\"ayahs\"][1]['text'])\n",
    "# # print(ayahs[-1].split('--- Paragraph ---'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98ef3f0c-163a-4f9c-a44a-4ca59ac02955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(text, surahs, cnt_surah):\n",
    "    data = { \"surahs\": [ ]} # surhas =  {\"number\":0, \"EnglishName\": \"Test\", \"ayahs\":[]} ]}\n",
    "\n",
    "\n",
    "    \n",
    "    pattern = r'\\(\\d+\\)'\n",
    "    \n",
    "    \n",
    "    for i, item in enumerate(text):\n",
    "        Surah = item\n",
    "        Surah_corrected = []\n",
    "    \n",
    "        ayahs = re.split(pattern, Surah)\n",
    "        ayahs = [section.strip().replace('\\n', '') for section in ayahs if section.strip()]\n",
    "    \n",
    "    \n",
    "    \n",
    "        for ayah in ayahs:\n",
    "            ayah = ayah.split('--- Paragraph ---')\n",
    "            if len(ayah) > 1:\n",
    "                \n",
    "                ayah_splited = merge_continuations(ayah)\n",
    "                cleaned_array = remove_extra_spaces(ayah_splited)\n",
    "                \n",
    "                Surah_corrected.append(convert(cleaned_array))\n",
    "            else:\n",
    "                Surah_corrected.append(ayah[0])\n",
    "                \n",
    "        cnt = -1\n",
    "        new_surah = {\"number\": cnt_surah + 1, \"EnglishName\": surahs[i], \"ayahs\":[]}\n",
    "        data[\"surahs\"].append(new_surah)\n",
    "        \n",
    "        # print(surahs[i], data[\"surahs\"])\n",
    "        for  new_ayah in Surah_corrected:\n",
    "            cnt += 1\n",
    "            if cnt == 0:\n",
    "                continue\n",
    "            d = {\"number\": cnt, \"text\": new_ayah}\n",
    "            data[\"surahs\"][i][\"ayahs\"].append(d)\n",
    "        \n",
    "    return data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "1eb6b834-7b58-41f6-9496-e7c5b90c11cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Toms = []\n",
    "num = 'I'\n",
    "for i in range(3):\n",
    "    with open(f'Tom_{num}.txt', 'r') as file:\n",
    "        text = file.read().split('ТОЛКОВАНИЕ')\n",
    "    num += 'I'\n",
    "\n",
    "    for i in range(len(text)):\n",
    "        \n",
    "        # text[i] = text[i].replace('\\n\\n', '$')   # – -\n",
    "        text[i] = text[i].replace('\\n', '')\n",
    "        # text[i] = text[i].replace('-', '')\n",
    "        text[i] = text[i].replace('\\uf072', 'да благословит его Аллах и приветствует')\n",
    "    text = text[1:]\n",
    "    Toms.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "45eb2e61-13f0-4561-99ff-2cf55a4f44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "surahs = [\n",
    "            ['Al-Faatiha', 'Al-Baqara', 'Aal-i-Imraan', 'An-Nisaa', 'Al-Maaida', \"Al-An'aam\", \"Al-A'raaf\", 'Al-Anfaal', 'At-Tawba', ],\n",
    "            ['Yunus', 'Hud', 'Yusuf', \"Ar-Ra'd\", 'Ibrahim', 'Al-Hijr', 'An-Nahl', 'Al-Israa', 'Al-Kahf', 'Maryam', 'Taa-Haa', 'Al-Anbiyaa', 'Al-Hajj', 'Al-Muminoon', 'An-Noor', 'Al-Furqaan', \"Ash-Shu'araa\", 'An-Naml', 'Al-Qasas', 'Al-Ankaboot', 'Ar-Room', ],\n",
    "            ['Luqman', 'As-Sajda', 'Al-Ahzaab', 'Saba', 'Faatir', 'Yaseen', 'As-Saaffaat', 'Saad', 'Az-Zumar', 'Ghafir', 'Fussilat', 'Ash-Shura', 'Az-Zukhruf', 'Ad-Dukhaan', 'Al-Jaathiya', 'Al-Ahqaf', 'Muhammad', 'Al-Fath', 'Al-Hujuraat', 'Qaaf', 'Adh-Dhaariyat', \n",
    "             'At-Tur', 'An-Najm', 'Al-Qamar', 'Ar-Rahmaan', 'Al-Waaqia', 'Al-Hadid', 'Al-Mujaadila', 'Al-Hashr', 'Al-Mumtahana', 'As-Saff', \"Al-Jumu'a\", 'Al-Munaafiqoon', 'At-Taghaabun', 'At-Talaaq', 'At-Tahrim', 'Al-Mulk', 'Al-Qalam', 'Al-Haaqqa', \"Al-Ma'aarij\", \n",
    "             'Nooh', 'Al-Jinn', 'Al-Muzzammil', 'Al-Muddaththir', 'Al-Qiyaama', 'Al-Insaan', 'Al-Mursalaat', 'An-Naba', \"An-Naazi'aat\", 'Abasa', 'At-Takwir', 'Al-Infitaar', 'Al-Mutaffifin', 'Al-Inshiqaaq', 'Al-Burooj', 'At-Taariq', \"Al-A'laa\", 'Al-Ghaashiya', 'Al-Fajr', \n",
    "             'Al-Balad', 'Ash-Shams', 'Al-Lail', 'Ad-Dhuhaa', 'Ash-Sharh', 'At-Tin', 'Al-Alaq', 'Al-Qadr', 'Al-Bayyina', 'Az-Zalzala', 'Al-Aadiyaat', \"Al-Qaari'a\", 'At-Takaathur', 'Al-Asr', 'Al-Humaza', 'Al-Fil', 'Quraish', \"Al-Maa'un\", 'Al-Kawthar', 'Al-Kaafiroon', \n",
    "             'An-Nasr', 'Al-Masad', 'Al-Ikhlaas', 'Al-Falaq', 'An-Naas']\n",
    "        ]\n",
    "\n",
    "\n",
    "final_dict = {\"surahs\":[]}\n",
    "list_of_Toms = []\n",
    "cnt_surah = 0\n",
    "for i, Tom in enumerate(Toms):\n",
    "    cnt_surah += len(surahs[i])\n",
    "    get = get_json(Tom, surahs[i], cnt_surah)\n",
    "    final_dict[\"surahs\"] += get[\"surahs\"]\n",
    "    list_of_Toms.append(get)\n",
    "    # print(len(surahs[i]), cnt_surah)\n",
    "\n",
    "# len(final_dict), len(Toms), len(list_of_Toms)\n",
    "formatted_json = json.dumps(final_dict, indent=4, ensure_ascii=False)\n",
    "with open('test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3f985d-602d-4216-ad4e-cd78d625a0a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b765f14-f5f9-471c-bd04-4f62411ccb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('structured_saadi.json', 'r') as file:\n",
    "    struct_saadi = json.load(file)\n",
    "\n",
    "with open('test.json', 'r') as file:\n",
    "    test_saadi = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "36983fd1-769f-49fe-a995-ddb5530ac99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n{'code': 200,\\n 'status': 'OK',\\n 'data': {'surahs': [{'number': 1,\\n    'name': 'سُورَةُ ٱلْفَاتِحَةِ',\\n    'englishName': 'Al-Faatiha',\\n    'englishNameTranslation': 'The Opening',\\n    'revelationType': 'Meccan',\\n    'ayahs': [{'number': 1,\\n      'text': 'Во имя Аллаха\\n\""
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------  TEST SAADI ------\n",
    "'''\n",
    "'surahs': [\n",
    "    {\n",
    "        'EnglishName': 'Al-Faatiha',\n",
    "        'ayahs': [\n",
    "               {\n",
    "                'number': 1,\n",
    "                'text': 'Во имя Аллаха, Милостивого\n",
    "'''\n",
    "\n",
    "# -------- STRUCTURED SAADI -----\n",
    "'''\n",
    "\"surahs\": [\n",
    "        {\n",
    "          \"englishName\": \"Al-Faatiha\"\n",
    "          \"ayahs\": [\n",
    "            {\n",
    "              \"number\": 1,\n",
    "              \"text\":\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "323fd06a-89f9-4501-acc6-f8c124c36bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_json = {}\n",
    "\n",
    "#add_newlines_to_text\n",
    "for i in range(len(struct_saadi[\"surahs\"])):\n",
    "    each_surah = struct_saadi[\"surahs\"][i]\n",
    "    test_each_surah = test_saadi[\"surahs\"][i]\n",
    "\n",
    "    \n",
    "    if each_surah[\"englishName\"] != test_each_surah[\"EnglishName\"]:\n",
    "        print(\"difference!!!!!\")\n",
    "    else:\n",
    "        for j in range(len(each_surah[\"ayahs\"])):\n",
    "            each_ayah = each_surah[\"ayahs\"][j][\"text\"]\n",
    "            test_each_ayah = test_each_surah[\"ayahs\"][j][\"text\"]\n",
    "\n",
    "            \n",
    "            \n",
    "            new_tafseer = add_newlines_to_text(each_ayah, test_each_ayah)\n",
    "            each_surah[\"ayahs\"][j][\"text\"] = new_tafseer\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e640579-f52f-4ecd-a87b-d035936bdb6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75d1d8a2-ee7b-4eb8-9f86-2102769190fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= SAVE FINAL JSON ======== \n",
    "# cleaned some places by hands\n",
    "\n",
    "# with open('new_saadi_tafseer.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(struct_saadi, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f81e05-212c-43e7-8bc4-3c2d912931c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_saadi_tafseer.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(struct_saadi, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea44b3d-8069-43f7-811e-3ea341a73869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a209e-510c-47e9-98f5-01f752f644cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbfdcb6-8270-4b78-b7fe-5a8bca9a7ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
